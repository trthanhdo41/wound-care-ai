{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13575364,"sourceType":"datasetVersion","datasetId":8624037},{"sourceId":13655542,"sourceType":"datasetVersion","datasetId":8681503}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:27:08.952888Z","iopub.execute_input":"2025-11-10T05:27:08.953304Z","iopub.status.idle":"2025-11-10T05:27:09.002269Z","shell.execute_reply.started":"2025-11-10T05:27:08.953277Z","shell.execute_reply":"2025-11-10T05:27:09.001437Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ✅ Cell 1: Import thư viện cần thiết","metadata":{}},{"cell_type":"code","source":"!pip install -q segmentation-models-pytorch albumentations timm\n\nimport os\nimport cv2\nimport random\nimport numpy as np\nimport pandas as pd\nfrom glob import glob\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport segmentation_models_pytorch as smp\n\ndef set_seed(seed: int = 42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(42)\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", DEVICE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:27:14.998429Z","iopub.execute_input":"2025-11-10T05:27:14.999256Z","iopub.status.idle":"2025-11-10T05:27:26.682668Z","shell.execute_reply.started":"2025-11-10T05:27:14.999228Z","shell.execute_reply":"2025-11-10T05:27:26.681800Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 2: Định nghĩa cấu hình chung + đọc danh sách (image, mask) cho train/val (no augmentation)","metadata":{}},{"cell_type":"code","source":"# thay thế\n# Cell 2: Cấu hình + tự động xác định DATA_DIR và thư mục masks linh hoạt (no augmentation)\n\nclass CFG:\n    IMG_SIZE = 512\n    EPOCHS = 80\n    BATCH_SIZE = 4\n    LR = 1e-4\n    NUM_WORKERS = 2\n    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n\n# 1) Tìm thư mục gốc có cấu trúc .../train/images\nROOT_SEARCH = \"/kaggle/input/thesis\"\n\ncandidate_roots = []\nfor root, dirs, files in os.walk(ROOT_SEARCH):\n    norm_root = root.replace(\"\\\\\", \"/\")\n    if norm_root.endswith(\"/train/images\"):\n        dataset_root = norm_root.rsplit(\"/train/images\", 1)[0]\n        candidate_roots.append(dataset_root)\n\ncandidate_roots = sorted(set(candidate_roots))\nprint(\"Candidate DATA_DIR found:\", candidate_roots)\n\nif len(candidate_roots) == 0:\n    raise FileNotFoundError(\n        \"Không tìm thấy thư mục train/images trong /kaggle/input/thesis. Kiểm tra lại cấu trúc dataset.\"\n    )\n\nDATA_DIR = candidate_roots[0]\nprint(\"Using DATA_DIR:\", DATA_DIR)\n\n# 2) Hàm tìm thư mục mask phù hợp (mask / masks / labels / segmentation...)\ndef find_mask_dir(split: str):\n    split_dir = os.path.join(DATA_DIR, split)\n    if not os.path.exists(split_dir):\n        raise FileNotFoundError(f\"Không tồn tại thư mục split: {split_dir}\")\n    \n    # Ưu tiên thư mục tên chứa 'mask' hoặc 'label'\n    candidates = []\n    for name in os.listdir(split_dir):\n        path = os.path.join(split_dir, name)\n        if os.path.isdir(path):\n            low = name.lower()\n            if \"mask\" in low or \"label\" in low or \"seg\" in low:\n                candidates.append(path)\n    \n    # Nếu không tìm thấy, fallback về 'masks'\n    if not candidates:\n        default_dir = os.path.join(split_dir, \"masks\")\n        if os.path.isdir(default_dir):\n            candidates.append(default_dir)\n    \n    if not candidates:\n        print(f\"[WARN] Không tìm thấy thư mục mask/label trong: {split_dir}\")\n        return None\n    \n    # Chọn candidate đầu tiên\n    mask_dir = sorted(candidates)[0]\n    print(f\"{split} mask_dir:\", mask_dir)\n    return mask_dir\n\ndef get_image_mask_pairs(split: str):\n    image_dir = os.path.join(DATA_DIR, split, \"images\")\n    if not os.path.isdir(image_dir):\n        print(f\"[WARN] Không tìm thấy {image_dir}\")\n        return []\n    \n    mask_dir = find_mask_dir(split)\n    if mask_dir is None:\n        return []\n    \n    image_paths = sorted(glob(os.path.join(image_dir, \"*\")))\n    exts = [\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\", \".bmp\"]\n    pairs = []\n\n    for img_path in image_paths:\n        base = os.path.splitext(os.path.basename(img_path))[0]\n        found_mask = None\n        for ext in exts:\n            cand = os.path.join(mask_dir, base + ext)\n            if os.path.exists(cand):\n                found_mask = cand\n                break\n        if found_mask is not None:\n            pairs.append((img_path, found_mask))\n\n    print(f\"{split} - found {len(pairs)} pairs\")\n    # In thử 3 cặp đầu để kiểm tra\n    for p in pairs[:3]:\n        print(\" sample:\", p[0], \"->\", p[1])\n    return pairs\n\ntrain_pairs = get_image_mask_pairs(\"train\")\nvalidation_pairs = get_image_mask_pairs(\"validation\")\n\nprint(\"Total train:\", len(train_pairs), \"| Total val:\", len(validation_pairs))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:27:30.159554Z","iopub.execute_input":"2025-11-10T05:27:30.160200Z","iopub.status.idle":"2025-11-10T05:27:30.244133Z","shell.execute_reply.started":"2025-11-10T05:27:30.160171Z","shell.execute_reply":"2025-11-10T05:27:30.243317Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell fix môi trường: khôi phục NumPy + Matplotlib tương thích (xử lý lỗi _ARRAY_API / multiarray)\n\n!pip install -q --force-reinstall \"numpy>=2.0.0,<2.3.0\" \"matplotlib>=3.8.0,<3.10.0\"\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nprint(\"NumPy version:\", np.__version__)\nprint(\"Matplotlib version:\", matplotlib.__version__)","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nsplit_names = [\"Train\", \"Validation\"]\nsplit_counts = [len(train_pairs), len(validation_pairs)]\n\nplt.figure(figsize=(5, 4))\nplt.bar(split_names, split_counts)\nplt.title(\"Dataset Split Overview (No Augmentation)\")\nplt.ylabel(\"Number of Image-Mask Pairs\")\nplt.grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\nfor i, v in enumerate(split_counts):\n    plt.text(i, v + 5, str(v), ha='center', fontsize=10)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:27:38.394404Z","iopub.execute_input":"2025-11-10T05:27:38.394713Z","iopub.status.idle":"2025-11-10T05:27:38.840482Z","shell.execute_reply.started":"2025-11-10T05:27:38.394691Z","shell.execute_reply":"2025-11-10T05:27:38.839690Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 3: Định nghĩa Dataset + DataLoader với transforms cơ bản (no augmentation)","metadata":{}},{"cell_type":"code","source":"class DFUSegDataset(Dataset):\n    def __init__(self, pairs, img_size=CFG.IMG_SIZE):\n        self.pairs = pairs\n        self.img_size = img_size\n        self.transform = A.Compose([\n            A.Resize(self.img_size, self.img_size),\n            A.Normalize(mean=(0.485, 0.456, 0.406),\n                        std=(0.229, 0.224, 0.225)),\n            ToTensorV2(),\n        ])\n\n    def __len__(self):\n        return len(self.pairs)\n\n    def __getitem__(self, idx):\n        img_path, mask_path = self.pairs[idx]\n\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n        # chuẩn về nhị phân 0/1\n        mask = (mask > 0).astype(\"float32\")\n\n        augmented = self.transform(image=image, mask=mask)\n        image = augmented[\"image\"]\n        mask = augmented[\"mask\"].unsqueeze(0)  # (1, H, W)\n\n        return image, mask\n\n# dùng train_pairs và val_pairs đã tạo ở Cell 2\ntrain_dataset = DFUSegDataset(train_pairs, img_size=CFG.IMG_SIZE)\nval_dataset = DFUSegDataset(validation_pairs, img_size=CFG.IMG_SIZE)\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=CFG.BATCH_SIZE,\n    shuffle=True,\n    num_workers=CFG.NUM_WORKERS,\n    pin_memory=True,\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=CFG.BATCH_SIZE,\n    shuffle=False,\n    num_workers=CFG.NUM_WORKERS,\n    pin_memory=True,\n)\n\nprint(\"Train batches:\", len(train_loader), \"| Val batches:\", len(val_loader))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:27:42.975183Z","iopub.execute_input":"2025-11-10T05:27:42.975992Z","iopub.status.idle":"2025-11-10T05:27:42.988796Z","shell.execute_reply.started":"2025-11-10T05:27:42.975966Z","shell.execute_reply":"2025-11-10T05:27:42.988108Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 4: Định nghĩa hàm loss BCE + Dice và các metric cơ bản (Dice, IoU, Precision, Recall)","metadata":{}},{"cell_type":"code","source":"def dice_coef(pred, target, smooth=1e-5):\n    pred = torch.sigmoid(pred)\n    pred = (pred > 0.5).float()\n    inter = (pred * target).sum(dim=(2, 3))\n    union = pred.sum(dim=(2, 3)) + target.sum(dim=(2, 3))\n    dice = (2.0 * inter + smooth) / (union + smooth)\n    return dice.mean().item()\n\ndef iou_coef(pred, target, smooth=1e-5):\n    pred = torch.sigmoid(pred)\n    pred = (pred > 0.5).float()\n    inter = (pred * target).sum(dim=(2, 3))\n    union = (pred + target - pred * target).sum(dim=(2, 3))\n    iou = (inter + smooth) / (union + smooth)\n    return iou.mean().item()\n\ndef bce_dice_loss(pred, target, smooth=1e-5):\n    bce = F.binary_cross_entropy_with_logits(pred, target)\n    pred_sig = torch.sigmoid(pred)\n    inter = (pred_sig * target).sum(dim=(2, 3))\n    union = pred_sig.sum(dim=(2, 3)) + target.sum(dim=(2, 3))\n    dice = 1 - ((2 * inter + smooth) / (union + smooth))\n    return bce + dice.mean()\n\nprint(\"✅ Defined: dice_coef, iou_coef, and bce_dice_loss\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:27:45.225570Z","iopub.execute_input":"2025-11-10T05:27:45.225912Z","iopub.status.idle":"2025-11-10T05:27:45.233903Z","shell.execute_reply.started":"2025-11-10T05:27:45.225847Z","shell.execute_reply":"2025-11-10T05:27:45.232899Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 5: Định nghĩa hàm train và validation cho 1 epoch (no augmentation)","metadata":{}},{"cell_type":"code","source":"import gc\n\ndef train_one_epoch(model, loader, optimizer):\n    model.train()\n    total_loss, total_dice, total_iou = 0.0, 0.0, 0.0\n\n    for images, masks in tqdm(loader, desc=\"Training\", leave=False):\n        images, masks = images.to(CFG.DEVICE), masks.to(CFG.DEVICE)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = bce_dice_loss(outputs, masks)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        total_dice += dice_coef(outputs, masks)\n        total_iou += iou_coef(outputs, masks)\n\n    mean_loss = total_loss / len(loader)\n    mean_dice = total_dice / len(loader)\n    mean_iou = total_iou / len(loader)\n\n    return mean_loss, mean_dice, mean_iou\n\n\n@torch.no_grad()\ndef valid_one_epoch(model, loader):\n    model.eval()\n    total_loss, total_dice, total_iou = 0.0, 0.0, 0.0\n\n    for images, masks in tqdm(loader, desc=\"Validation\", leave=False):\n        images, masks = images.to(CFG.DEVICE), masks.to(CFG.DEVICE)\n\n        outputs = model(images)\n        loss = bce_dice_loss(outputs, masks)\n\n        total_loss += loss.item()\n        total_dice += dice_coef(outputs, masks)\n        total_iou += iou_coef(outputs, masks)\n\n    mean_loss = total_loss / len(loader)\n    mean_dice = total_dice / len(loader)\n    mean_iou = total_iou / len(loader)\n\n    return mean_loss, mean_dice, mean_iou\n\n\ndef train_model(model, model_name, num_epochs=CFG.EPOCHS):\n    model = model.to(CFG.DEVICE)\n    optimizer = torch.optim.Adam(model.parameters(), lr=CFG.LR)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode=\"min\", factor=0.5, patience=5, verbose=True\n    )\n\n    best_dice = 0.0\n    best_loss = np.inf\n\n    history = {\n        \"train_loss\": [],\n        \"val_loss\": [],\n        \"train_dice\": [],\n        \"val_dice\": [],\n        \"train_iou\": [],\n        \"val_iou\": [],\n    }\n\n    save_path = f\"{model_name}_best_no_aug.pth\"\n\n    for epoch in range(1, num_epochs + 1):\n        print(f\"\\n===== {model_name} | Epoch {epoch}/{num_epochs} =====\")\n\n        torch.cuda.empty_cache()\n        gc.collect()\n\n        train_loss, train_dice, train_iou = train_one_epoch(model, train_loader, optimizer)\n        val_loss, val_dice, val_iou = valid_one_epoch(model, val_loader)\n\n        scheduler.step(val_loss)\n\n        history[\"train_loss\"].append(train_loss)\n        history[\"val_loss\"].append(val_loss)\n        history[\"train_dice\"].append(train_dice)\n        history[\"val_dice\"].append(val_dice)\n        history[\"train_iou\"].append(train_iou)\n        history[\"val_iou\"].append(val_iou)\n\n        print(\n            f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | \"\n            f\"Train Dice: {train_dice:.4f} | Val Dice: {val_dice:.4f} | \"\n            f\"Train IoU: {train_iou:.4f} | Val IoU: {val_iou:.4f}\"\n        )\n\n        if val_dice > best_dice:\n            best_dice = val_dice\n            best_loss = val_loss\n            torch.save(model.state_dict(), save_path)\n            print(f\"✅ Saved best model: {save_path} (Val Dice: {best_dice:.4f})\")\n\n    print(f\"\\nBest Val Dice for {model_name}: {best_dice:.4f} (Loss: {best_loss:.4f})\")\n    return model, history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:27:47.458670Z","iopub.execute_input":"2025-11-10T05:27:47.459679Z","iopub.status.idle":"2025-11-10T05:27:47.473212Z","shell.execute_reply.started":"2025-11-10T05:27:47.459651Z","shell.execute_reply":"2025-11-10T05:27:47.472314Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 6: Định nghĩa hàm train_model()","metadata":{}},{"cell_type":"code","source":"def train_model(model, model_name, num_epochs=CFG.EPOCHS):\n    model = model.to(CFG.DEVICE)\n    optimizer = torch.optim.Adam(model.parameters(), lr=CFG.LR)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode=\"min\", factor=0.5, patience=5, verbose=True\n    )\n\n    best_dice = 0.0\n    best_loss = np.inf\n\n    history = {\n        \"train_loss\": [],\n        \"val_loss\": [],\n        \"train_dice\": [],\n        \"val_dice\": [],\n        \"train_iou\": [],\n        \"val_iou\": [],\n    }\n\n    save_path = f\"{model_name}_best_no_aug.pth\"\n\n    for epoch in range(1, num_epochs + 1):\n        print(f\"\\n===== {model_name} | Epoch {epoch}/{num_epochs} =====\")\n\n        torch.cuda.empty_cache()\n        gc.collect()\n\n        # nhận đủ 3 giá trị\n        train_loss, train_dice, train_iou = train_one_epoch(model, train_loader, optimizer)\n        val_loss, val_dice, val_iou = valid_one_epoch(model, val_loader)\n\n        scheduler.step(val_loss)\n\n        history[\"train_loss\"].append(train_loss)\n        history[\"val_loss\"].append(val_loss)\n        history[\"train_dice\"].append(train_dice)\n        history[\"val_dice\"].append(val_dice)\n        history[\"train_iou\"].append(train_iou)\n        history[\"val_iou\"].append(val_iou)\n\n        print(\n            f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | \"\n            f\"Train Dice: {train_dice:.4f} | Val Dice: {val_dice:.4f} | \"\n            f\"Train IoU: {train_iou:.4f} | Val IoU: {val_iou:.4f}\"\n        )\n\n        if val_dice > best_dice:\n            best_dice = val_dice\n            best_loss = val_loss\n            torch.save(model.state_dict(), save_path)\n            print(f\"✅ Saved best model: {save_path} (Val Dice: {best_dice:.4f})\")\n\n    print(f\"\\nBest Val Dice for {model_name}: {best_dice:.4f} (Loss: {best_loss:.4f})\")\n    return model, history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:27:51.702487Z","iopub.execute_input":"2025-11-10T05:27:51.702797Z","iopub.status.idle":"2025-11-10T05:27:51.710794Z","shell.execute_reply.started":"2025-11-10T05:27:51.702773Z","shell.execute_reply":"2025-11-10T05:27:51.710005Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 7: Huấn luyện mô hình đầu tiên (U-Net++) làm baseline chưa augmentation","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport gc\n\n# đảm bảo batch size an toàn cho GPU\nCFG.BATCH_SIZE = 2\n\ntorch.cuda.empty_cache()\ngc.collect()\n\n# Khởi tạo mô hình U-Net++ (nhẹ)\nmodel_unetpp = smp.UnetPlusPlus(\n    encoder_name=\"efficientnet-b0\",\n    encoder_weights=\"imagenet\",\n    in_channels=3,\n    classes=1,\n)\n\n# Huấn luyện\nmodel_unetpp, hist_unetpp = train_model(model_unetpp, model_name=\"UNetPP_NoAug\")\n\n# --- Vẽ biểu đồ ---\nepochs = range(1, len(hist_unetpp[\"train_loss\"]) + 1)\n\nplt.figure(figsize=(15,4))\n\n# (1) Loss\nplt.subplot(1,3,1)\nplt.plot(epochs, hist_unetpp[\"train_loss\"], label=\"Train Loss\")\nplt.plot(epochs, hist_unetpp[\"val_loss\"], label=\"Val Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"Train vs Val Loss (U-Net++)\")\nplt.legend()\nplt.grid(alpha=0.3)\n\n# (2) Dice\nplt.subplot(1,3,2)\nplt.plot(epochs, hist_unetpp[\"train_dice\"], label=\"Train Dice\")\nplt.plot(epochs, hist_unetpp[\"val_dice\"], label=\"Val Dice\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Dice\")\nplt.title(\"Train vs Val Dice (U-Net++)\")\nplt.legend()\nplt.grid(alpha=0.3)\n\n# (3) IoU\nplt.subplot(1,3,3)\nplt.plot(epochs, hist_unetpp[\"train_iou\"], label=\"Train IoU\")\nplt.plot(epochs, hist_unetpp[\"val_iou\"], label=\"Val IoU\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"IoU\")\nplt.title(\"Train vs Val IoU (U-Net++)\")\nplt.legend()\nplt.grid(alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T05:27:54.745588Z","iopub.execute_input":"2025-11-10T05:27:54.746508Z","iopub.status.idle":"2025-11-10T05:28:04.679961Z","shell.execute_reply.started":"2025-11-10T05:27:54.746483Z","shell.execute_reply":"2025-11-10T05:28:04.678747Z"}},"outputs":[],"execution_count":null}]}