#!/usr/bin/env python
# coding: utf-8

# In[33]:


# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session


# # 1. C√†i ƒë·∫∑t th∆∞ vi·ªán

# In[3]:


get_ipython().system('pip install -q segmentation-models-pytorch albumentations timm opencv-python-headless numpy scikit-image matplotlib grad-cam')

# 2. Import c√°c th∆∞ vi·ªán
import torch
import torch.nn as nn
import cv2
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from glob import glob
import os

# Import th∆∞ vi·ªán model
import segmentation_models_pytorch as smp

# Import th∆∞ vi·ªán x·ª≠ l√Ω ·∫£nh (transform)
import albumentations as A
from albumentations.pytorch import ToTensorV2

# Import th∆∞ vi·ªán cho GLCM (ph√¢n t√≠ch g·ªì gh·ªÅ)
from skimage.feature import graycomatrix, graycoprops

# Import th∆∞ vi·ªán cho Grad-CAM
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.model_targets import SemanticSegmentationTarget
from pytorch_grad_cam.utils.image import show_cam_on_image

print("Cell 1: Th∆∞ vi·ªán cho Notebook m·ªõi ƒë√£ s·∫µn s√†ng!")


# # 1. ƒê·ªãnh nghƒ©a Config (ch·ªâ nh·ªØng g√¨ c·∫ßn cho inference)

# In[4]:


class CFG:
    IMG_SIZE = 512
    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

print(f"S·ª≠ d·ª•ng device: {CFG.DEVICE}")
print(f"S·ª≠ d·ª•ng IMG_SIZE: {CFG.IMG_SIZE}")


# 2. ƒê·ªãnh nghƒ©a l·∫°i transform D√ôNG CHO INFERENCE
# (Gi·ªëng h·ªát transform l√∫c validation)
inference_transform = A.Compose([
    A.Resize(CFG.IMG_SIZE, CFG.IMG_SIZE),
    A.Normalize(mean=(0.485, 0.456, 0.406),
                std=(0.229, 0.224, 0.225)),
    ToTensorV2(),
])
print("ƒê√£ t·∫°o 'inference_transform'.")


# 3. Kh·ªüi t·∫°o c·∫•u tr√∫c model v√† Load weights

MODEL_PATH = "/kaggle/input/model-trained/Model Trained/SegFormerB3_NoAug_best_no_aug (1).pth" # S·ª≠a ƒë∆∞·ªùng d·∫´n n√†y

# Ki·ªÉm tra xem file c√≥ t·ªìn t·∫°i kh√¥ng
if not os.path.exists(MODEL_PATH):
    print(f"L·ªñI: Kh√¥ng t√¨m th·∫•y file model t·∫°i '{MODEL_PATH}'")
    print("Vui l√≤ng ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n v√† upload file .pth l√™n Kaggle.")
    # S·∫Ω b√°o l·ªói ·ªü ƒë√¢y n·∫øu s·∫øp kh√¥ng s·ª≠a ƒë∆∞·ªùng d·∫´n

# Ph·∫£i ƒë·ªãnh nghƒ©a l·∫°i model y h·ªát l√∫c train
model_inference = smp.Unet(
    encoder_name="mit_b3",
    encoder_weights=None, # ƒê·∫∑t l√† None v√¨ ta s·∫Ω load file pth
    in_channels=3,
    classes=1,
)

# 4. Load weights ƒë√£ train
try:
    model_inference.load_state_dict(torch.load(MODEL_PATH, map_location=CFG.DEVICE))
    model_inference.to(CFG.DEVICE)
    model_inference.eval() # B·∫¨T CH·∫æ ƒê·ªò INFERENCE
    print(f"‚úÖ‚úÖ‚úÖ S·∫µn s√†ng! ƒê√£ load model t·ª´ {MODEL_PATH}")
except Exception as e:
    print(f"L·ªñI KHI LOAD MODEL: {e}")
    print("N·∫øu l·ªói 'No such file or directory', s·∫øp h√£y s·ª≠a MODEL_PATH ·ªü tr√™n.")


# In[5]:


TEST_IMAGE_PATH = "/kaggle/input/thesis/Dataset (S/test/images/1343.png" # S·ª≠a ƒë∆∞·ªùng d·∫´n n√†y

# 1. H√†m ƒë·ªÉ load v√† x·ª≠ l√Ω ·∫£nh (V√Å L·ªñI)
def load_and_transform_image(image_path):
    if not os.path.exists(image_path):
        print(f"L·ªñI 1: Kh√¥ng t√¨m th·∫•y ƒë∆∞·ªùng d·∫´n '{image_path}'")
        return None, None

    original_image = cv2.imread(image_path)

    if original_image is None:
        print(f"L·ªñI 2: cv2.imread kh√¥ng th·ªÉ ƒë·ªçc ƒë∆∞·ª£c file t·∫°i: '{image_path}'")
        print("L√Ω do: File h·ªèng, ho·∫∑c ƒë∆∞·ªùng d·∫´n sai (c√≥ th·ªÉ c√≥ k√Ω t·ª± l·∫°).")
        return None, None

    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)

    transformed = inference_transform(image=original_image)
    input_tensor = transformed["image"]
    input_tensor = input_tensor.unsqueeze(0).to(CFG.DEVICE)

    print(f"ƒê√£ load v√† transform ·∫£nh: {image_path}")
    print(f"K√≠ch th∆∞·ªõc tensor ƒë·∫ßu v√†o: {input_tensor.shape}")

    return original_image, input_tensor

# 2. H√†m ƒë·ªÉ ch·∫°y prediction (Gi·ªØ nguy√™n)
@torch.no_grad()
def get_prediction_mask(input_tensor):
    if input_tensor is None:
        return None

    logits = model_inference(input_tensor)
    probabilities = torch.sigmoid(logits)
    predicted_mask = (probabilities > 0.5).float()
    predicted_mask = predicted_mask.squeeze().cpu().numpy()

    print(f"ƒê√£ t·∫°o predicted mask, k√≠ch th∆∞·ªõc: {predicted_mask.shape}")
    return predicted_mask

# 3. Ch·∫°y th·ª±c t·∫ø
original_image, input_tensor = load_and_transform_image(TEST_IMAGE_PATH)
predicted_mask = get_prediction_mask(input_tensor)

# 4. Hi·ªÉn th·ªã k·∫øt qu·∫£
if predicted_mask is not None and original_image is not None:
    fig, ax = plt.subplots(1, 3, figsize=(18, 6))

    original_resized = cv2.resize(original_image, (CFG.IMG_SIZE, CFG.IMG_SIZE))

    ax[0].imshow(original_resized)
    ax[0].set_title(f"·∫¢nh G·ªëc (Resized {CFG.IMG_SIZE}x{CFG.IMG_SIZE})")
    ax[0].axis("off")

    ax[1].imshow(predicted_mask, cmap='gray')
    ax[1].set_title("Predicted Mask (Binary)")
    ax[1].axis("off")

    # Hi·ªÉn th·ªã mask ƒë√® l√™n ·∫£nh g·ªëc
    overlay = original_resized.copy()

    # === S·ª¨A L·ªñI VALUEERROR T·∫†I ƒê√ÇY ===
    # 1. KH√îNG c·∫ßn t·∫°o mask_3d
    # 2. D√πng th·∫≥ng predicted_mask (2D) ƒë·ªÉ ch·ªçn pixel tr√™n overlay (3D)

    # `predicted_mask > 0` s·∫Ω ch·ªçn ra c√°c pixel (H, W)
    # NumPy s·∫Ω t·ª± ƒë·ªông g√°n c·∫£ 3 k√™nh (R, G, B) c·ªßa pixel ƒë√≥
    overlay[predicted_mask > 0] = (255, 0, 0) # T√¥ m√†u ƒë·ªè v√†o v√πng mask
    # ==================================

    ax[2].imshow(overlay)
    ax[2].set_title("Mask Overlay")
    ax[2].axis("off")

    plt.tight_layout()
    plt.show()
else:
    print("Kh√¥ng th·ªÉ hi·ªÉn th·ªã. Vui l√≤ng ki·ªÉm tra l·∫°i l·ªói ·ªü tr√™n.")


# In[6]:


# Cell n√†y s·∫Ω c√†i th√™m pandas, tqdm, v√† scikit-learn
get_ipython().system('pip install -q pandas tqdm scikit-learn')
import pandas as pd
from tqdm import tqdm
from glob import glob
import os
import random
from sklearn.utils import shuffle

print("--- B∆Ø·ªöC 1: L·∫§Y M·∫™U PIXEL (T·ª™ TRAIN+VALID) ---")

# --- PH·∫¶N 1: C√ÅC H√ÄM TI·ªÜN √çCH ---

# 1. Config (l·∫•y t·ª´ Cell 2)
if 'CFG' not in globals():
    class CFG:
        IMG_SIZE = 512 # L·∫•y l·∫°i t·ª´ Cell 2
        DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(f"S·∫Ω resize ·∫£nh/mask v·ªÅ: {CFG.IMG_SIZE}x{CFG.IMG_SIZE}")

# 2. ‚ö†Ô∏è S·ª¨A ƒê∆Ø·ªúNG D·∫™N DATA G·ªêC
DATA_DIR = "/kaggle/input/thesis/Dataset (S" # S·ª≠a l·∫°i n·∫øu c·∫ßn

# 3. H√†m ti·ªán √≠ch ƒë·ªÉ t√¨m c√°c c·∫∑p (·∫£nh, mask)
def find_all_pairs(data_dir):
    all_pairs = []
    splits = ["train", "validation"]
    for split in splits:
        image_dir = os.path.join(data_dir, split, "images")
        mask_dir_name = "masks" # Gi·∫£ ƒë·ªãnh t√™n
        if not os.path.exists(os.path.join(data_dir, split, mask_dir_name)):
             mask_dir_name = "labels"
        mask_dir = os.path.join(data_dir, split, mask_dir_name)
        if not os.path.exists(image_dir) or not os.path.exists(mask_dir):
            print(f"C·∫£nh b√°o: Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c images/masks cho split '{split}'")
            continue
        print(f"ƒêang qu√©t {split}...")
        image_paths = sorted(glob(os.path.join(image_dir, "*")))
        for img_path in image_paths:
            base_name_no_ext = os.path.splitext(os.path.basename(img_path))[0]
            found_mask = None
            for ext in [".png", ".jpg", ".jpeg"]:
                mask_cand = os.path.join(mask_dir, base_name_no_ext + ext)
                if os.path.exists(mask_cand):
                    found_mask = mask_cand
                    break
            if found_mask:
                all_pairs.append((img_path, found_mask, split))
    return all_pairs

# --- PH·∫¶N 2: CH·∫†Y V√íNG L·∫∂P (CH·ªà ƒê·ªÇ "H√öT" PIXEL) ---

# 1. T·∫°o danh s√°ch 1000+ c·∫∑p file
all_image_pairs = find_all_pairs(DATA_DIR)
print(f"\nT·ªïng c·ªông t√¨m th·∫•y: {len(all_image_pairs)} c·∫∑p (·∫£nh, mask).")

# 2. V√≤ng l·∫∑p "h√∫t" pixel
all_wound_pixels = [] # N∆°i gom pixel t·ª´ 1000+ ·∫£nh

for img_path, mask_path, split in tqdm(all_image_pairs, desc="H√∫t pixel t·ª´ Train/Valid"):
    try:
        # 2a. Load ·∫¢nh v√† Mask (D√ôNG LABEL TH·∫¨T)
        image_bgr = cv2.imread(img_path)
        mask_gray = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

        if image_bgr is None or mask_gray is None:
            continue

        # 2b. Resize
        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
        image_resized = cv2.resize(image_rgb, (CFG.IMG_SIZE, CFG.IMG_SIZE), 
                                   interpolation=cv2.INTER_LANCZOS4)
        mask_resized = cv2.resize(mask_gray, (CFG.IMG_SIZE, CFG.IMG_SIZE), 
                                  interpolation=cv2.INTER_NEAREST)

        # 2c. L·∫•y mask (boolean)
        mask_bool = (mask_resized > 0)

        # 2d. "H√∫t" pixel
        current_pixels = image_resized[mask_bool] # Shape (N, 3)

        if len(current_pixels) > 0:
            all_wound_pixels.append(current_pixels)

    except Exception as e:
        print(f"L·ªói khi x·ª≠ l√Ω file {img_path}: {e}")

print(f"\nƒê√£ gom pixel t·ª´ {len(all_wound_pixels)} v·∫øt lo√©t (·∫£nh).")

# --- PH·∫¶N 3: T·ªîNG H·ª¢P M·∫™U "PH·ªî QU√ÅT" ---

if not all_wound_pixels:
    print("L·ªñI: Kh√¥ng h√∫t ƒë∆∞·ª£c pixel n√†o. Ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n.")
else:
    # 1. Gom t·∫•t c·∫£ l·∫°i th√†nh 1 m·∫£ng numpy kh·ªïng l·ªì
    pixel_mega_array = np.concatenate(all_wound_pixels, axis=0)
    print(f"T·ªïng c·ªông ƒë√£ h√∫t ƒë∆∞·ª£c: {len(pixel_mega_array)} pixels.")

    # 2. L·∫•y m·∫´u cu·ªëi c√πng
    # Ch·∫°y Elbow/Silhouette tr√™n 500k pixel l√† ƒë·ªß
    FINAL_SAMPLE_SIZE = 500000 

    if len(pixel_mega_array) > FINAL_SAMPLE_SIZE:
        print(f"L·∫•y m·∫´u ng·∫´u nhi√™n {FINAL_SAMPLE_SIZE} pixels t·ª´ t·ªïng...")
        # D√πng shuffle c·ªßa sklearn cho hi·ªáu qu·∫£
        final_pixel_sample = shuffle(pixel_mega_array, 
                                     random_state=42)[:FINAL_SAMPLE_SIZE]
    else:
        print("L·∫•y to√†n b·ªô pixel l√†m m·∫´u.")
        final_pixel_sample = pixel_mega_array

    print(f"‚úÖ Ho√†n t·∫•t B∆∞·ªõc 1! ƒê√£ c√≥ m·∫´u 'ph·ªï qu√°t' v·ªõi {len(final_pixel_sample)} pixels.")
    print("Bi·∫øn 'final_pixel_sample' ƒë√£ s·∫µn s√†ng cho B∆∞·ªõc 2.")


# In[8]:


# === B∆Ø·ªöC 2: RGB -> HSV & CHU·∫®N H√ìA CHO K-MEANS ===

import numpy as np
import cv2

print("--- B∆Ø·ªöC 2: CONVERT RGB -> HSV & T·∫†O FEATURE ---")

# 1. Ki·ªÉm tra xem ƒë√£ c√≥ m·∫´u pixel ch∆∞a
if 'final_pixel_sample' not in globals():
    raise ValueError("‚ùå final_pixel_sample ch∆∞a t·ªìn t·∫°i. Nh·ªõ ch·∫°y B∆∞·ªõc 1 tr∆∞·ªõc ƒë√£!")

# 2. ƒê·∫£m b·∫£o ki·ªÉu d·ªØ li·ªáu ƒë√∫ng cho OpenCV
# final_pixel_sample shape: (N, 3), m·ªói row = [R, G, B]
pixels_rgb = final_pixel_sample.astype(np.uint8)

print(f"S·ªë pixel m·∫´u ƒëang c√≥: {pixels_rgb.shape[0]}")

# 3. Reshape ƒë·ªÉ d√πng cv2.cvtColor (c·∫ßn shape (N, 1, 3))
pixels_rgb_reshaped = pixels_rgb.reshape(-1, 1, 3)

# 4. Convert RGB -> HSV (OpenCV d√πng Hue: 0‚Äì179, S/V: 0‚Äì255)
pixels_hsv_reshaped = cv2.cvtColor(pixels_rgb_reshaped, cv2.COLOR_RGB2HSV)
pixels_hsv = pixels_hsv_reshaped.reshape(-1, 3)

# 5. In th·ª≠ v√†i pixel ƒë·ªÉ xem RGB vs HSV nh∆∞ th·∫ø n√†o
print("\nV√≠ d·ª• 5 pixel ƒë·∫ßu ti√™n (RGB -> HSV):")
print("RGB:")
print(pixels_rgb[:5])
print("HSV (H,S,V):")
print(pixels_hsv[:5])

# 6. Chu·∫©n h√≥a HSV v·ªÅ [0,1] ƒë·ªÉ d√πng cho K-means / ML
#    - OpenCV: H ‚àà [0,179], S ‚àà [0,255], V ‚àà [0,255]
h = pixels_hsv[:, 0].astype(np.float32) / 179.0
s = pixels_hsv[:, 1].astype(np.float32) / 255.0
v = pixels_hsv[:, 2].astype(np.float32) / 255.0

# 7. Gh√©p l·∫°i th√†nh feature matrix X_hsv (N, 3)
X_hsv = np.stack([h, s, v], axis=1)

print(f"\n‚úÖ ƒê√£ t·∫°o feature HSV cho K-means v·ªõi shape: {X_hsv.shape}")
print("   M·ªói row = [H_norm, S_norm, V_norm] ‚àà [0,1]")

# 8. (Optional) L∆∞u ra file ƒë·ªÉ x√†i ·ªü notebook kh√°c / b∆∞·ªõc sau
np.save("wound_pixels_hsv_sample.npy", X_hsv)
print("\nüíæ ƒê√£ l∆∞u feature HSV v√†o file: 'wound_pixels_hsv_sample.npy'")
print("   B∆∞·ªõc ti·∫øp theo: ch·∫°y K-means tr√™n X_hsv (B∆∞·ªõc 3).")


# In[9]:


# === B∆Ø·ªöC 3: K-MEANS COLOR CLUSTERING TR√äN X_hsv ===
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import numpy as np
import matplotlib.pyplot as plt

print("--- B∆Ø·ªöC 3: K-MEANS TR√äN PIXEL HSV (COLOR CLUSTERING) ---")

# 1. Ki·ªÉm tra d·ªØ li·ªáu ƒë·∫ßu v√†o
if 'X_hsv' not in globals():
    raise ValueError("‚ùå X_hsv ch∆∞a t·ªìn t·∫°i. Nh·ªõ ch·∫°y B∆∞·ªõc 2 (RGB -> HSV) tr∆∞·ªõc!")

N = X_hsv.shape[0]
print(f"T·ªïng s·ªë pixel trong X_hsv: {N}")

# 2. L·∫•y m·∫´u con cho vi·ªác t√¨m s·ªë c·ª•m (cho ƒë·ª° n·∫∑ng)
MAX_SAMPLE_FOR_K = 100000  # m√†y c√≥ th·ªÉ ch·ªânh l√™n/xu·ªëng
if N > MAX_SAMPLE_FOR_K:
    print(f"L·∫•y m·∫´u ng·∫´u nhi√™n {MAX_SAMPLE_FOR_K} pixel ƒë·ªÉ ch·∫°y Elbow/Silhouette...")
    idx = np.random.choice(N, size=MAX_SAMPLE_FOR_K, replace=False)
    X_sample = X_hsv[idx]
else:
    print("D√πng to√†n b·ªô X_hsv ƒë·ªÉ ch·∫°y Elbow/Silhouette.")
    X_sample = X_hsv

print(f"Shape m·∫´u d√πng cho K-means: {X_sample.shape}")

# 3. Th·ª≠ nhi·ªÅu gi√° tr·ªã K ƒë·ªÉ xem Elbow + Silhouette
K_list = [2, 3, 4, 5, 6]
inertias = []
sil_scores = []

print("\nƒêang ch·∫°y K-means cho c√°c K:", K_list)
for K in K_list:
    print(f"  -> ƒêang fit KMeans v·ªõi K = {K} ...")
    kmeans_tmp = KMeans(
        n_clusters=K,
        random_state=42,
        n_init=10
    )
    labels_tmp = kmeans_tmp.fit_predict(X_sample)
    inertias.append(kmeans_tmp.inertia_)

    # Silhouette ch·ªâ meaningful khi K > 1
    if K > 1:
        sil = silhouette_score(X_sample, labels_tmp)
    else:
        sil = np.nan
    sil_scores.append(sil)

print("\nK·∫øt qu·∫£ Elbow (Inertia) & Silhouette:")
for K, inertia, sil in zip(K_list, inertias, sil_scores):
    print(f"K = {K}: inertia = {inertia:.2f}, silhouette = {sil:.4f}")

# 4. V·∫Ω Elbow & Silhouette cho d·ªÖ nh√¨n (optional)
plt.figure(figsize=(10,4))

plt.subplot(1,2,1)
plt.plot(K_list, inertias, marker='o')
plt.xlabel("S·ªë c·ª•m K")
plt.ylabel("Inertia (Within-Cluster SSE)")
plt.title("Elbow Method")

plt.subplot(1,2,2)
plt.plot(K_list, sil_scores, marker='o')
plt.xlabel("S·ªë c·ª•m K")
plt.ylabel("Silhouette Score")
plt.title("Silhouette Score theo K")

plt.tight_layout()
plt.show()

print("\nüí° G·ª£i √Ω:")
print("- Th∆∞·ªùng v·ªõi DFU color risk, ng∆∞·ªùi ta hay ch·ªçn kho·∫£ng K = 3 (ƒë·ªè / v√†ng / s·∫≠m/tr·∫Øng).")
print("- Nh∆∞ng m√†y n√™n nh√¨n Elbow + Silhouette r·ªìi quy·∫øt ƒë·ªãnh K h·ª£p l√Ω cho dataset c·ªßa m√†y.")

# 5. TRAIN M√î H√åNH KMEANS CU·ªêI C√ôNG V·ªöI K ƒê√É CH·ªåN
#    (·ªû ƒë√¢y tao ƒë·ªÉ default l√† 3, m√†y c√≥ th·ªÉ ƒë·ªïi sau khi xem plot)
BEST_K = 3
print(f"\n--- TRAIN KMEANS FINAL V·ªöI K = {BEST_K} TR√äN TO√ÄN B·ªò X_hsv ---")

kmeans_final = KMeans(
    n_clusters=BEST_K,
    random_state=42,
    n_init=10
)
cluster_labels_full = kmeans_final.fit_predict(X_hsv)
cluster_centers_hsv = kmeans_final.cluster_centers_

print("‚úÖ ƒê√£ train xong KMeans final.")
print(f"Shape cluster_centers_hsv: {cluster_centers_hsv.shape}")
print("C√°c t√¢m c·ª•m (H_norm, S_norm, V_norm) trong [0,1]:")
print(cluster_centers_hsv)

# 6. (Optional) L∆∞u model/t√¢m c·ª•m ƒë·ªÉ d√πng ·ªü b∆∞·ªõc risk level
import joblib
joblib.dump(kmeans_final, "kmeans_ulcer_color_hsv.pkl")
np.save("kmeans_ulcer_color_centers_hsv.npy", cluster_centers_hsv)

print("\nüíæ ƒê√£ l∆∞u model KMeans v√†o 'kmeans_ulcer_color_hsv.pkl'")
print("   v√† t√¢m c·ª•m v√†o 'kmeans_ulcer_color_centers_hsv.npy'.")

# Sau n√†y m√†y c√≥ th·ªÉ load l·∫°i:
# kmeans_loaded = joblib.load("kmeans_ulcer_color_hsv.pkl")


# In[11]:


# === B∆Ø·ªöC 2 + 3 G·ªòP: RGB -> HSV + KMEANS K=3 ===
import numpy as np
import cv2
from sklearn.cluster import KMeans
import joblib
import pandas as pd

print("--- B∆Ø·ªöC 2+3: RGB -> HSV & KMEANS K=3 TR√äN TO√ÄN B·ªò PIXEL ---")

# 1. Ki·ªÉm tra final_pixel_sample (t·ª´ B∆∞·ªõc 1)
if 'final_pixel_sample' not in globals():
    raise ValueError("‚ùå final_pixel_sample ch∆∞a t·ªìn t·∫°i. Nh·ªõ ch·∫°y cell h√∫t pixel (B∆∞·ªõc 1) tr∆∞·ªõc!")

# 2. Chu·∫©n b·ªã pixel RGB
pixels_rgb = final_pixel_sample.astype(np.uint8)  # shape (N, 3)
N = pixels_rgb.shape[0]
print(f"S·ªë pixel m·∫´u ƒëang c√≥: {N}")

# 3. RGB -> HSV (OpenCV: H‚àà[0,179], S,V‚àà[0,255])
pixels_rgb_reshaped = pixels_rgb.reshape(-1, 1, 3)
pixels_hsv_reshaped = cv2.cvtColor(pixels_rgb_reshaped, cv2.COLOR_RGB2HSV)
pixels_hsv = pixels_hsv_reshaped.reshape(-1, 3)

# 4. Chu·∫©n h√≥a v·ªÅ [0,1] ƒë·ªÉ K-means d·ªÖ h·ªçc
h = pixels_hsv[:, 0].astype(np.float32) / 179.0
s = pixels_hsv[:, 1].astype(np.float32) / 255.0
v = pixels_hsv[:, 2].astype(np.float32) / 255.0
X_hsv = np.stack([h, s, v], axis=1)

print(f"‚úÖ ƒê√£ t·∫°o X_hsv v·ªõi shape: {X_hsv.shape} (H_norm, S_norm, V_norm ‚àà [0,1])")

# 5. Train K-means FINAL v·ªõi K = 3 tr√™n to√†n b·ªô X_hsv
BEST_K = 3
print(f"\n--- TRAIN KMEANS FINAL V·ªöI K = {BEST_K} ---")

kmeans_final = KMeans(
    n_clusters=BEST_K,
    random_state=42,
    n_init=10
)
cluster_labels_full = kmeans_final.fit_predict(X_hsv)
cluster_centers_hsv = kmeans_final.cluster_centers_

print("‚úÖ ƒê√£ train xong KMeans.")
print("T√¢m c·ª•m (H_norm, S_norm, V_norm):")
print(cluster_centers_hsv)

# 6. L∆∞u model + t√¢m c·ª•m
joblib.dump(kmeans_final, "kmeans_ulcer_color_hsv.pkl")
np.save("kmeans_ulcer_color_centers_hsv.npy", cluster_centers_hsv)

print("\nüíæ ƒê√£ l∆∞u model v√†o 'kmeans_ulcer_color_hsv.pkl'")
print("üíæ ƒê√£ l∆∞u t√¢m c·ª•m v√†o 'kmeans_ulcer_color_centers_hsv.npy'")

# 7. (Optional) L∆∞u t√¢m c·ª•m ra CSV cho d·ªÖ d√πng trong b√°o c√°o
df_centers = pd.DataFrame(
    cluster_centers_hsv,
    columns=["H_norm", "S_norm", "V_norm"]
)
df_centers.to_csv("kmeans_color_cluster_centers.csv", index=False)
print("üíæ ƒê√£ l∆∞u t√¢m c·ª•m ra CSV: 'kmeans_color_cluster_centers.csv'")

print("\nüëâ Gi·ªù m√†y ƒë√£ c√≥:")
print("- X_hsv  (feature pixel HSV chu·∫©n h√≥a)")
print("- kmeans_final (model K=3)")
print("- cluster_centers_hsv (3 m√†u ƒë·∫°i di·ªán)")
print("- file CSV t√¢m c·ª•m ƒë·ªÉ ƒë∆∞a v√†o thesis/report.")


# In[17]:


# === B∆Ø·ªöC 4 (UPDATED): T√çNH % RED / YELLOW / DARK-LIKE CHO T·ª™NG ·∫¢NH ===
import cv2
import numpy as np
import pandas as pd
from glob import glob
import os

print("--- B∆Ø·ªöC 4: COLOR FEATURES PER IMAGE (RED / YELLOW / DARK-LIKE) ---")

# 1. Ki·ªÉm tra model K-means K=3
if 'kmeans_final' not in globals():
    raise ValueError("‚ùå kmeans_final ch∆∞a t·ªìn t·∫°i. H√£y ch·∫°y cell train K=3 tr∆∞·ªõc.")

# Mapping cluster index -> t√™n m√†u
# üéØ D·ª±a tr√™n t√¢m c·ª•m m√†y ƒë√£ ƒë∆∞a:
# 0 ‚Üí reddish
# 1 ‚Üí yellowish
# 2 ‚Üí dark-like
cluster_to_name = {
    0: "red_like",
    1: "yellow_like",
    2: "dark_like"
}

# 2. Ki·ªÉm tra DATA_DIR
if 'DATA_DIR' not in globals():
    raise ValueError("‚ùå DATA_DIR ch∆∞a t·ªìn t·∫°i. Nh·ªõ set t·ª´ B∆∞·ªõc 1.")

# --- H√ÄM T√çNH FEATURE M√ÄU CHO 1 ·∫¢NH ---
def compute_color_features_for_image(img_path, mask_path):
    img_bgr = cv2.imread(img_path)
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

    if img_bgr is None or mask is None:
        return None

    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
    mask_bool = mask > 0

    if mask_bool.sum() == 0:
        return None

    # L·∫•y pixel v√πng lo√©t
    ulcer_pixels = img_rgb[mask_bool].astype(np.uint8)

    # RGB -> HSV
    reshaped = ulcer_pixels.reshape(-1, 1, 3)
    hsv = cv2.cvtColor(reshaped, cv2.COLOR_RGB2HSV).reshape(-1, 3)

    # Normalize
    h = hsv[:,0] / 179.0
    s = hsv[:,1] / 255.0
    v = hsv[:,2] / 255.0
    X = np.stack([h, s, v], axis=1)

    # üî• FIX: √âp v·ªÅ float64
    X = X.astype(np.float64)

    # üî• FIX: √âp T√ÇM C·ª§M v·ªÅ float64 (ƒë·ªÉ match v·ªõi X)
    kmeans_final.cluster_centers_ = kmeans_final.cluster_centers_.astype(np.float64)

    # Predict cluster
    labels = kmeans_final.predict(X)
    total = len(labels)

    pct_red = np.sum(labels == 0) / total
    pct_yellow = np.sum(labels == 1) / total
    pct_dark = np.sum(labels == 2) / total

    return {
        "img_name": os.path.basename(img_path),
        "pct_red_like": pct_red,
        "pct_yellow_like": pct_yellow,
        "pct_dark_like": pct_dark,
        "num_pixels": total
    }




# --- QU√âT TRAIN + VALID V√Ä T√çNH FEATURE ---
splits = ["train", "validation"]
all_results = []

for split in splits:
    img_dir = os.path.join(DATA_DIR, split, "images")
    mask_dir = os.path.join(DATA_DIR, split, "masks")
    if not os.path.exists(mask_dir):
        mask_dir = os.path.join(DATA_DIR, split, "labels")

    img_paths = sorted(glob(os.path.join(img_dir, "*")))

    print(f"\nƒêang x·ª≠ l√Ω split: {split} ‚Äî {len(img_paths)} ·∫£nh")

    for img_path in img_paths:
        base = os.path.splitext(os.path.basename(img_path))[0]

        # t√¨m mask ·ª©ng v·ªõi t√™n ·∫£nh
        mask_path = None
        for ext in [".png", ".jpg", ".jpeg"]:
            c = os.path.join(mask_dir, base + ext)
            if os.path.exists(c):
                mask_path = c
                break

        if mask_path is None:
            continue

        res = compute_color_features_for_image(img_path, mask_path)
        if res is not None:
            res["split"] = split
            all_results.append(res)

print("\nHo√†n t·∫•t t√≠nh feature. S·ªë ·∫£nh x·ª≠ l√Ω:", len(all_results))

# --- XU·∫§T CSV ---
df_color_features = pd.DataFrame(all_results)
df_color_features.to_csv("color_features_ulcer_red_yellow_dark.csv", index=False)

print("üíæ ƒê√£ l∆∞u file: color_features_ulcer_red_yellow_dark.csv")
df_color_features.head()


# In[18]:


# Cell n√†y c·∫ßn c√°c bi·∫øn:
# - predicted_mask (t·ª´ Cell 10)  -> mask model segment, 0/1 ho·∫∑c 0..1
# - original_resized (t·ª´ Cell 10) -> ·∫£nh RGB ƒë√£ resize
# - kmeans_final (model KMeans K=3 ƒë√£ train tr√™n HSV pixel)
# - np, cv2, plt (ƒë√£ import)

print("--- CELL DEMO: PH√ÇN T√çCH M√ÄU (1 ·∫¢NH TEST) ---")

if 'predicted_mask' not in globals() or 'original_resized' not in globals():
    print("L·ªñI: Kh√¥ng t√¨m th·∫•y 'predicted_mask' ho·∫∑c 'original_resized'.")
    print("S·∫øp ch·∫°y l·∫°i Cell 10 ƒë·ªÉ load ·∫£nh test + mask.")
elif 'kmeans_final' not in globals():
    print("L·ªñI: Kh√¥ng t√¨m th·∫•y 'kmeans_final'. Nh·ªõ ch·∫°y cell train K-means K=3 tr∆∞·ªõc.")
else:
    # 1. Chu·∫©n b·ªã mask (uint8, 0-255)
    # predicted_mask c√≥ th·ªÉ l√† 0/1 float, n√™n m√¨nh threshold nh·∫π cho ch·∫Øc
    mask_bool = predicted_mask > 0.5
    mask_uint8 = (mask_bool.astype(np.uint8) * 255)

    if mask_bool.sum() == 0:
        print("L·ªñI: Mask kh√¥ng c√≥ pixel n√†o > 0, kh√¥ng ph√¢n t√≠ch m√†u ƒë∆∞·ª£c.")
    else:
        # 2. L·∫•y pixel v√πng lo√©t t·ª´ original_resized (gi·∫£ ƒë·ªãnh l√† RGB)
        ulcer_pixels = original_resized[mask_bool].astype(np.uint8)  # (N, 3)

        # 3. RGB -> HSV
        ulcer_reshaped = ulcer_pixels.reshape(-1, 1, 3)
        hsv = cv2.cvtColor(ulcer_reshaped, cv2.COLOR_RGB2HSV).reshape(-1, 3)

        # 4. Chu·∫©n ho√° v·ªÅ [0,1]
        h = hsv[:, 0] / 179.0
        s = hsv[:, 1] / 255.0
        v = hsv[:, 2] / 255.0
        X = np.stack([h, s, v], axis=1)

        # 5. √âp ki·ªÉu cho kh·ªõp v·ªõi KMeans
        X = X.astype(np.float64)
        kmeans_final.cluster_centers_ = kmeans_final.cluster_centers_.astype(np.float64)

        # 6. D·ª± ƒëo√°n c·ª•m m√†u
        labels = kmeans_final.predict(X)
        total = len(labels)

        # Mapping: 0 = red-like, 1 = yellow-like, 2 = dark-like
        pct_red   = np.sum(labels == 0) / total
        pct_yel   = np.sum(labels == 1) / total
        pct_dark  = np.sum(labels == 2) / total

        text_red  = f"Red-like    : {pct_red:.3f}"
        text_yel  = f"Yellow-like : {pct_yel:.3f}"
        text_dark = f"Dark-like   : {pct_dark:.3f}"

        print("--- B√ÅO C√ÅO M√ÄU (·∫¢NH TEST) ---")
        print(text_red)
        print(text_yel)
        print(text_dark)

        # 7. V·∫Ω overlay mask + info text (gi·ªëng style Cell k√≠ch th∆∞·ªõc)
        overlay_display = original_resized.copy()
        contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if len(contours) > 0:
            main_contour = max(contours, key=cv2.contourArea)
            cv2.drawContours(overlay_display, [main_contour], -1, (0, 255, 0), 2)  # vi·ªÅn xanh l√°

        plt.figure(figsize=(12, 5))

        # 7.1 ·∫¢nh + mask overlay + text
        plt.subplot(1, 2, 1)
        plt.imshow(overlay_display)
        plt.title("·∫¢nh test + ƒë∆∞·ªùng vi·ªÅn v·∫øt lo√©t")
        plt.axis("off")
        plt.text(10, 30, text_red,  color='white', fontsize=11,
                 bbox=dict(facecolor='black', alpha=0.5))
        plt.text(10, 55, text_yel,  color='white', fontsize=11,
                 bbox=dict(facecolor='black', alpha=0.5))
        plt.text(10, 80, text_dark, color='white', fontsize=11,
                 bbox=dict(facecolor='black', alpha=0.5))

        # 7.2 Bi·ªÉu ƒë·ªì c·ªôt % 3 m√†u
        plt.subplot(1, 2, 2)
        labels_bar = ["Red-like", "Yellow-like", "Dark-like"]
        values_bar = [pct_red, pct_yel, pct_dark]
        plt.bar(labels_bar, values_bar)
        plt.ylim(0, 1.0)
        plt.ylabel("T·ªâ l·ªá pixel")
        plt.title("Th√†nh ph·∫ßn m√†u c·ªßa v·∫øt lo√©t (HSV K-means)")
        for i, v in enumerate(values_bar):
            plt.text(i, v + 0.02, f"{v:.2f}", ha="center")

        plt.tight_layout()
        plt.show()


# In[20]:


# N·∫øu df_color_features v·∫´n c√≤n trong RAM:
if 'df_color_features' in globals():
    # ƒê·ªïi img_name -> image_name cho kh·ªõp v·ªõi B∆∞·ªõc 6
    df_color_features = df_color_features.rename(columns={"img_name": "image_name"})
    # Copy sang df_features_final ƒë·ªÉ B∆∞·ªõc 6 x√†i
    df_features_final = df_color_features.copy()
else:
    # Tr∆∞·ªùng h·ª£p m√†y ƒë√£ l∆∞u CSV r·ªìi, ch·ªâ c√≤n file
    df_color_features = pd.read_csv("color_features_ulcer_red_yellow_dark.csv")
    df_color_features = df_color_features.rename(columns={"img_name": "image_name"})
    df_features_final = df_color_features.copy()

print("df_features_final ready, 5 d√≤ng ƒë·∫ßu:")
print(df_features_final.head())


# In[21]:


# Cell n√†y c·∫ßn:
# - df_features_final (t·ª´ Cell 9, ch·ª©a % m√†u)
# - all_image_pairs (t·ª´ Cell 5, danh s√°ch 1010 file)
# - CFG.IMG_SIZE (t·ª´ Cell 5)
# - np, cv2, tqdm, pd (ƒë√£ import)

print("--- B∆Ø·ªöC 6: Th√™m K√≠ch th∆∞·ªõc / H√¨nh th√°i (Size/Morphology) ---")

# --- PH·∫¶N 1: ƒê·ªäNH NGHƒ®A H√ÄM ---
def analyze_morphology(mask_gt_uint8):
    """
    T√≠nh to√°n di·ªán t√≠ch, chu vi, ƒë·ªô tr√≤n t·ª´ MASK TH·∫¨T (uint8, 0-255).
    """
    pixel_area = 0.0
    perimeter = 0.0
    circularity = 0.0

    # 1. Di·ªán t√≠ch (t√≠nh b·∫±ng c√°ch ƒë·∫øm pixel)
    pixel_area = np.sum(mask_gt_uint8 > 0)

    if pixel_area == 0:
        return 0.0, 0.0, 0.0 # Tr·∫£ v·ªÅ 0 n·∫øu mask r·ªóng

    # 2. T√¨m contours
    contours, _ = cv2.findContours(mask_gt_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    if len(contours) > 0:
        main_contour = max(contours, key=cv2.contourArea)

        # 3. Chu vi
        perimeter = cv2.arcLength(main_contour, True)

        # 4. ƒê·ªô tr√≤n
        if perimeter > 0:
            circularity = (4 * np.pi * pixel_area) / (perimeter**2)

    return pixel_area, perimeter, circularity

print("‚úÖ ƒê√£ n·∫°p h√†m 'analyze_morphology'.")

# --- PH·∫¶N 2: CH·∫†Y V√íNG L·∫∂P (CH·ªà T√çNH K√çCH TH∆Ø·ªöC) ---

# 1. Ki·ªÉm tra bi·∫øn
if 'all_image_pairs' not in globals():
    print("L·ªñI: Kh√¥ng t√¨m th·∫•y 'all_image_pairs'. S·∫øp ch·∫°y l·∫°i Cell 5.")
else:
    all_features_morphology = [] # N∆°i l∆∞u k·∫øt qu·∫£ K√≠ch th∆∞·ªõc

    for img_path, mask_path, split in tqdm(all_image_pairs, desc="Ph√¢n t√≠ch K√≠ch th∆∞·ªõc (1010 ·∫£nh)"):
        try:
            # 2a. Ch·ªâ Load Mask (Label th·∫≠t)
            mask_gray = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

            if mask_gray is None:
                continue

            # 2b. Resize
            mask_resized = cv2.resize(mask_gray, (CFG.IMG_SIZE, CFG.IMG_SIZE), 
                                      interpolation=cv2.INTER_NEAREST)

            # 2c. Chu·∫©n h√≥a Mask v·ªÅ 0-255 (uint8)
            mask_gt_uint8 = (mask_resized > 0).astype(np.uint8) * 255

            # 2d. G·ªçi h√†m
            area, peri, circ = analyze_morphology(mask_gt_uint8)

            # 2e. L∆∞u k·∫øt qu·∫£
            feature_dict = {
                "image_name": os.path.basename(img_path),
                "area_pixels": area,
                "perimeter": peri,
                "circularity": circ
            }
            all_features_morphology.append(feature_dict)

        except Exception as e:
            print(f"L·ªói khi x·ª≠ l√Ω file {img_path}: {e}")

    print(f"\n‚úÖ‚úÖ‚úÖ Ho√†n t·∫•t ph√¢n t√≠ch K√≠ch th∆∞·ªõc!")

    # --- PH·∫¶N 3: GH√âP (MERGE) V√ÄO DATAFRAME CH√çNH ---

    if 'df_features_final' not in globals():
        print("L·ªñI: Kh√¥ng t√¨m th·∫•y 'df_features_final' (t·ª´ Cell 9).")
    else:
        # 1. T·∫°o DataFrame K√≠ch th∆∞·ªõc
        df_morphology = pd.DataFrame(all_features_morphology)

        # 2. Gh√©p (Merge)
        print("ƒêang gh√©p (merge) DataFrame K√≠ch th∆∞·ªõc v√†o DataFrame M√†u s·∫Øc...")
        df_features_final = pd.merge(
            df_features_final,  # DataFrame t·ª´ Cell 9 (c√≥ % m√†u)
            df_morphology,      # DataFrame m·ªõi (c√≥ area, peri)
            on="image_name",    # Gh√©p b·∫±ng t√™n file
            how="left"          # Gi·ªØ t·∫•t c·∫£ d√≤ng t·ª´ df_features_final
        )

        # 3. L∆∞u file CSV
        CSV_PATH_FINAL = "wound_features_dataset.csv" # T√™n file t·ª´ Cell 9
        df_features_final.to_csv(CSV_PATH_FINAL, index=False)

        print(f"‚úÖ ƒê√£ gh√©p v√† l∆∞u file: {CSV_PATH_FINAL}")

        # 4. Hi·ªÉn th·ªã 5 d√≤ng ƒë·∫ßu (v·ªõi c√°c c·ªôt m·ªõi)
        print("\n--- 5 d√≤ng ƒë·∫ßu c·ªßa DataFrame (ƒê√£ th√™m K√≠ch th∆∞·ªõc): ---")
        print(df_features_final.head())


# In[1]:


# Cell n√†y c·∫ßn c√°c bi·∫øn:
# - predicted_mask (t·ª´ Cell 10)
# - original_resized (t·ª´ Cell 10)
# - H√†m analyze_morphology (t·ª´ Cell 11)
# - np, cv2, plt (ƒë√£ import)

print("--- CELL 12: DEMO K√çCH TH∆Ø·ªöC / H√åNH TH√ÅI (1 ·∫¢NH TEST) ---")

# 1. Ki·ªÉm tra bi·∫øn
if 'predicted_mask' not in globals() or 'original_resized' not in globals():
    print("L·ªñI: Kh√¥ng t√¨m th·∫•y 'predicted_mask' ho·∫∑c 'original_resized'.")
    print("S·∫øp vui l√≤ng ch·∫°y l·∫°i Cell 10 ƒë·ªÉ load ·∫£nh test.")
elif 'analyze_morphology' not in globals():
    print("L·ªñI: Kh√¥ng t√¨m th·∫•y h√†m 'analyze_morphology'. S·∫øp ch·∫°y l·∫°i Cell 11.")
else:
    # 2. Chu·∫©n b·ªã mask (uint8, 0-255)
    mask_uint8 = (predicted_mask * 255).astype(np.uint8)

    # 3. T√≠nh to√°n
    area, peri, circ = analyze_morphology(mask_uint8)

    # 4. T·∫°o ·∫£nh Overlay
    overlay_display = original_resized.copy()

    # T√¨m v√† v·∫Ω contour
    contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if len(contours) > 0:
        main_contour = max(contours, key=cv2.contourArea)
        # V·∫Ω vi·ªÅn contour (m√†u xanh l√°, d√†y 2px)
        cv2.drawContours(overlay_display, [main_contour], -1, (0, 255, 0), 2)

    # 5. T·∫°o text ƒë·ªÉ in l√™n ·∫£nh
    text_area = f"Dien tich (Area): {area:.0f} pixels"
    text_peri = f"Chu vi (Perimeter): {peri:.2f} pixels"
    text_circ = f"Do tron (Circularity): {circ:.4f}"

    print("--- B√ÅO C√ÅO K√çCH TH∆Ø·ªöC (·∫¢NH TEST) ---")
    print(text_area)
    print(text_peri)
    print(text_circ)

    # 6. V·∫Ω plot
    plt.figure(figsize=(10, 10))
    plt.imshow(overlay_display)

    # ƒê·∫∑t ti√™u ƒë·ªÅ
    plt.title("Phan tich Kich thuoc / Hinh thai")

    # In 3 d√≤ng text l√™n ·∫£nh
    # (x=10, y=30) l√† t·ªça ƒë·ªô (pixel)
    plt.text(10, 30, text_area, color='white', fontsize=12, 
             bbox=dict(facecolor='black', alpha=0.5))
    plt.text(10, 60, text_peri, color='white', fontsize=12, 
             bbox=dict(facecolor='black', alpha=0.5))
    plt.text(10, 90, text_circ, color='white', fontsize=12, 
             bbox=dict(facecolor='black', alpha=0.5))

    plt.axis("off")
    plt.show()


# In[23]:


# Cell n√†y c·∫ßn c√°c bi·∫øn:
# - predicted_mask (t·ª´ Cell 10)
# - original_resized (t·ª´ Cell 10)
# - th∆∞ vi·ªán: numpy, cv2, matplotlib, skimage

import numpy as np
import cv2
import matplotlib.pyplot as plt
from skimage.feature import graycomatrix, graycoprops

print("--- CELL 13 (Update 3 - FIX L·ªñI): DEMO G·ªí GH·ªÄ ---")

# --- 1. ƒê·ªäNH NGHƒ®A H√ÄM ANALYZE_TEXTURE T·∫†I CH·ªñ (CHO CH·∫ÆC ƒÇN) ---
def analyze_texture(image_rgb, mask_gt_uint8):
    """
    T√≠nh GLCM (Contrast, Homogeneity) t·ª´ MASK (uint8, 0-255).
    """
    if np.sum(mask_gt_uint8) == 0:
        return 0.0, 0.0, 0.0, 0.0 # Mask r·ªóng

    # Chuy·ªÉn sang ·∫£nh x√°m
    gray_image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)

    try:
        # T√¨m bounding box ƒë·ªÉ c·∫Øt ROI (t·ªëi ∆∞u t·ªëc ƒë·ªô)
        rows = np.any(mask_gt_uint8, axis=1)
        cols = np.any(mask_gt_uint8, axis=0)
        rmin, rmax = np.where(rows)[0][[0, -1]]
        cmin, cmax = np.where(cols)[0][[0, -1]]

        # C·∫Øt ROI (V√πng ·∫£nh x√°m)
        roi_gray = gray_image[rmin:rmax+1, cmin:cmax+1]
        roi_mask = mask_gt_uint8[rmin:rmax+1, cmin:cmax+1]

        # G√°n 0 cho v√πng n·ªÅn (ƒë·ªÉ GLCM b·ªè qua)
        roi_gray[roi_mask == 0] = 0

        # T√≠nh GLCM
        glcm = graycomatrix(roi_gray, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)
        glcm[0,0,:,:] = 0 # B·ªè qua c·∫∑p (0,0) (n·ªÅn-n·ªÅn)

        contrast = graycoprops(glcm, 'contrast')[0, 0]
        homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]
        energy = graycoprops(glcm, 'energy')[0, 0]
        correlation = graycoprops(glcm, 'correlation')[0, 0]

        return contrast, homogeneity, energy, correlation
    except Exception as e:
        print(f"L·ªói t√≠nh GLCM: {e}")
        return 0.0, 0.0, 0.0, 0.0

print("‚úÖ ƒê√£ ƒë·ªãnh nghƒ©a l·∫°i h√†m 'analyze_texture'.")


# --- 2. CH·∫†Y T√çNH TO√ÅN V√Ä V·∫º ---
if 'predicted_mask' not in globals() or 'original_resized' not in globals():
    print("L·ªñI: S·∫øp ch·∫°y l·∫°i Cell 10 ƒë·ªÉ load ·∫£nh test tr∆∞·ªõc nh√©.")
else:
    # Chu·∫©n b·ªã mask
    mask_uint8 = (predicted_mask * 255).astype(np.uint8)

    # T√≠nh to√°n
    con, homo, ener, corr = analyze_texture(original_resized, mask_uint8)

    print("--- B√ÅO C√ÅO G·ªí GH·ªÄ (·∫¢NH TEST) ---")
    print(f"Contrast (Tuong phan): {con:.4f}")
    print(f"Homogeneity (Dong nhat): {homo:.4f}")

    # L·∫•y ·∫£nh Grayscale ROI ƒë·ªÉ show
    gray_image_resized = cv2.cvtColor(original_resized, cv2.COLOR_RGB2GRAY)
    roi_display = np.zeros_like(gray_image_resized)
    roi_display[mask_uint8 > 0] = gray_image_resized[mask_uint8 > 0]

    # --- V·∫º PLOT (T√ÅCH L√ÄM 3 C·ªòT) ---
    fig, ax = plt.subplots(1, 3, figsize=(22, 7))

    # Plot 1: ·∫¢nh x√°m
    ax[0].imshow(roi_display, cmap='gray')
    ax[0].set_title("Vung vet loet (Grayscale)", fontsize=16)
    ax[0].axis("off")

    # Plot 2: Contrast
    bars_con = ax[1].barh(['Contrast'], [con], color='blue')
    ax[1].set_title("Contrast (Do go ghe)", fontsize=16)
    ax[1].set_xlabel("Gia tri (Cang cao cang go ghe)", fontsize=12)
    ax[1].tick_params(axis='y', labelsize=14)
    ax[1].set_xlim(0, con * 1.2) # Scale
    ax[1].text(con + (con * 0.01), 0, f"{con:.4f}", va='center', fontsize=12)

    # Plot 3: Homogeneity
    bars_homo = ax[2].barh(['Homogeneity'], [homo], color='green')
    ax[2].set_title("Homogeneity (Do dong nhat)", fontsize=16)
    ax[2].set_xlabel("Gia tri (Cang thap cang go ghe)", fontsize=12)
    ax[2].tick_params(axis='y', labelsize=14)
    ax[2].set_xlim(0, 1.0) # Scale 0-1
    ax[2].text(homo + 0.01, 0, f"{homo:.4f}", va='center', fontsize=12)

    plt.tight_layout(pad=3.0)
    plt.show()


# In[24]:


# Cell n√†y c·∫ßn c√°c bi·∫øn:
# - predicted_mask (t·ª´ Cell 10)
# - original_resized (t·ª´ Cell 10)
# - C·∫ßn h√†m analyze_color (ƒë√£ ƒë·ªãnh nghƒ©a ·ªü Cell 4 c·ªßa flow CSV)
# - np, cv2, plt (ƒë√£ import)

print("--- CELL 14: DEMO PH√ÇN T√çCH V√ôNG DA XUNG QUANH (PERIWOUND) ---")

# --- PH·∫¶N 1: ƒê·ªäNH NGHƒ®A H√ÄM (Cho ch·∫Øc) ---

# (H√†m n√†y ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a ·ªü Cell 4 c·ªßa flow CSV,
# nh∆∞ng ta ƒë·ªãnh nghƒ©a l·∫°i cho ch·∫Øc)
def analyze_color(image_rgb, mask_uint8):
    mask_bool = mask_uint8.astype(bool)
    if np.sum(mask_bool) == 0:
        return (0,0,0), (0,0,0), (0,0,0)

    # Lab (Quan tr·ªçng nh·∫•t)
    try:
        lab_image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2Lab)
        pixels_lab = lab_image[mask_bool]
        mean_lab = np.mean(pixels_lab, axis=0)
    except Exception:
        mean_lab = (0,0,0)

    # RGB
    try:
        pixels_rgb = image_rgb[mask_bool]
        mean_rgb = np.mean(pixels_rgb, axis=0)
    except Exception:
        mean_rgb = (0,0,0)

    # HSV
    try:
        hsv_image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2HSV)
        pixels_hsv = hsv_image[mask_bool]
        mean_hsv = np.mean(pixels_hsv, axis=0)
    except Exception:
        mean_hsv = (0,0,0)

    return mean_rgb, mean_hsv, mean_lab

print("‚úÖ ƒê√£ n·∫°p h√†m 'analyze_color'.")


# --- PH·∫¶N 2: CH·∫†Y DEMO ---

if 'predicted_mask' not in globals() or 'original_resized' not in globals():
    print("L·ªñI: Ch·∫°y l·∫°i Cell 10 ƒë·ªÉ load ·∫£nh test.")
else:
    # 1. Chu·∫©n b·ªã mask (uint8, 0-255)
    mask_uint8 = (predicted_mask * 255).astype(np.uint8)

    # 2. T·∫°o "v√≤ng" (ring)
    PERIWOUND_WIDTH = 15 # S·∫øp c√≥ th·ªÉ ch·ªânh ƒë·ªô r·ªông (15 pixels)
    kernel_size = (PERIWOUND_WIDTH * 2) + 1
    kernel = np.ones((kernel_size, kernel_size), np.uint8)

    # 2a. Th·ªïi ph·ªìng (Dilate)
    dilated_mask = cv2.dilate(mask_uint8, kernel, iterations=1)

    # 2b. Tr·ª´ ƒëi -> L·∫•y c√°i "v√≤ng"
    periwound_mask = cv2.subtract(dilated_mask, mask_uint8)

    # 3. Ph√¢n t√≠ch m√†u s·∫Øc tr√™n "v√≤ng"
    (r,g,b), (h,s,v), (l,a,b) = analyze_color(original_resized, periwound_mask)

    print("--- B√ÅO C√ÅO V√ôNG DA XUNG QUANH ---")
    print(f"L* (Do sang): {l:.2f}")
    print(f"a* (Do do/luc): {a:.2f} (Cang duong -> cang do -> viem)")
    print(f"b* (Do vang/xanh): {b:.2f} (Cang duong -> cang vang)")

    # 4. T·∫°o ·∫£nh Overlay (v·∫Ω c√°i v√≤ng)
    overlay_display = original_resized.copy()
    # V·∫Ω mask v·∫øt lo√©t (m√†u ƒë·ªè)
    overlay_display[predicted_mask > 0] = (255, 0, 0)
    # V·∫Ω "v√≤ng" periwound (m√†u xanh l√°)
    overlay_display[periwound_mask > 0] = (0, 255, 0)


    # --- PH·∫¶N 3: V·∫º PLOT ---
    fig, ax = plt.subplots(1, 2, figsize=(18, 9))

    # Plot 1: ·∫¢nh Overlay
    ax[0].imshow(overlay_display)
    ax[0].set_title("Phan tich Periwound\n(Vet loet = Do, Vung xung quanh = Xanh)", fontsize=16)
    ax[0].axis("off")

    # Plot 2: Bi·ªÉu ƒë·ªì c·ªôt cho Lab (quan tr·ªçng nh·∫•t)
    features = ['L* (Do sang)', 'a* (Do do)', 'b* (Do vang)']
    values = [l, a, b]
    colors = ['gray', 'red', 'yellow']

    bars = ax[1].barh(features, values, color=colors)
    ax[1].set_title("Mau sac vung da xung quanh (Lab)", fontsize=16)
    ax[1].set_xlabel("Gia tri", fontsize=14)
    ax[1].tick_params(axis='y', labelsize=14)

    # Th√™m text gi√° tr·ªã
    for bar in bars:
        width = bar.get_width()
        ax[1].text(width + 0.5, # V·ªã tr√≠ text
                   bar.get_y() + bar.get_height()/2,
                   f"{width:.2f}",
                   va='center', fontsize=12)

    plt.tight_layout(pad=3.0)
    plt.show()


# In[25]:


# Cell 12: Th√™m G·ªì gh·ªÅ (Texture) v√† V√πng da xung quanh (Periwound) v√†o CSV

# Cell n√†y c·∫ßn:
# - df_features_final (t·ª´ Cell 11, ho·∫∑c load t·ª´ file CSV)
# - all_image_pairs (t·ª´ Cell 5)
# - CFG.IMG_SIZE, CFG.DEVICE
# - th∆∞ vi·ªán: np, cv2, tqdm, pd, graycomatrix, graycoprops

print("--- B∆Ø·ªöC 7: Th√™m G·ªì gh·ªÅ (Texture) & V√πng da xung quanh (Periwound) ---")

# --- PH·∫¶N 1: ƒê·ªäNH NGHƒ®A H√ÄM ---

# 1. H√†m Texture (GLCM)
def analyze_texture(image_rgb, mask_gt_uint8):
    if np.sum(mask_gt_uint8) == 0:
        return 0.0, 0.0, 0.0, 0.0

    gray_image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)

    try:
        # T√¨m bounding box ƒë·ªÉ c·∫Øt ROI (cho nhanh)
        rows = np.any(mask_gt_uint8, axis=1)
        cols = np.any(mask_gt_uint8, axis=0)
        rmin, rmax = np.where(rows)[0][[0, -1]]
        cmin, cmax = np.where(cols)[0][[0, -1]]

        roi_gray = gray_image[rmin:rmax+1, cmin:cmax+1]
        roi_mask = mask_gt_uint8[rmin:rmax+1, cmin:cmax+1]

        # G√°n n·ªÅn = 0
        roi_gray[roi_mask == 0] = 0

        # T√≠nh GLCM
        glcm = graycomatrix(roi_gray, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)
        glcm[0,0,:,:] = 0 # B·ªè qua c·∫∑p (0,0)

        contrast = graycoprops(glcm, 'contrast')[0, 0]
        homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]
        energy = graycoprops(glcm, 'energy')[0, 0]
        correlation = graycoprops(glcm, 'correlation')[0, 0]

        return contrast, homogeneity, energy, correlation
    except Exception:
        return 0.0, 0.0, 0.0, 0.0

# 2. H√†m Periwound (V√πng da xung quanh)
def analyze_periwound(image_rgb, mask_gt_uint8, width=15):
    # T·∫°o kernel
    kernel_size = (width * 2) + 1
    kernel = np.ones((kernel_size, kernel_size), np.uint8)

    # Th·ªïi ph·ªìng
    dilated_mask = cv2.dilate(mask_gt_uint8, kernel, iterations=1)

    # Tr·ª´ ƒëi -> V√≤ng
    periwound_mask = cv2.subtract(dilated_mask, mask_gt_uint8)

    # T√≠nh m√†u trung b√¨nh (Lab)
    mask_bool = periwound_mask.astype(bool)
    if np.sum(mask_bool) == 0:
        return 0.0, 0.0, 0.0 # Kh√¥ng c√≥ v√πng xung quanh (mask ch·∫°m vi·ªÅn?)

    lab_image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2Lab)
    pixels_lab = lab_image[mask_bool]
    mean_lab = np.mean(pixels_lab, axis=0)

    return mean_lab[0], mean_lab[1], mean_lab[2] # L, a, b

print("‚úÖ ƒê√£ n·∫°p h√†m 'analyze_texture' v√† 'analyze_periwound'.")


# --- PH·∫¶N 2: CH·∫†Y V√íNG L·∫∂P ---

# 1. Ki·ªÉm tra bi·∫øn
if 'all_image_pairs' not in globals():
    print("L·ªñI: Kh√¥ng t√¨m th·∫•y 'all_image_pairs'. S·∫øp ch·∫°y l·∫°i Cell 5.")
else:
    all_features_extra = []
    PERIWOUND_WIDTH = 15 # ƒê·ªô r·ªông

    for img_path, mask_path, split in tqdm(all_image_pairs, desc="Ph√¢n t√≠ch Texture & Periwound"):
        try:
            # Load ·∫¢nh + Mask
            image_bgr = cv2.imread(img_path)
            mask_gray = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

            if image_bgr is None or mask_gray is None:
                continue

            # Resize
            image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
            image_resized = cv2.resize(image_rgb, (CFG.IMG_SIZE, CFG.IMG_SIZE), interpolation=cv2.INTER_LANCZOS4)
            mask_resized = cv2.resize(mask_gray, (CFG.IMG_SIZE, CFG.IMG_SIZE), interpolation=cv2.INTER_NEAREST)

            mask_gt_uint8 = (mask_resized > 0).astype(np.uint8) * 255

            # 1. T√≠nh Texture
            con, homo, ener, corr = analyze_texture(image_resized, mask_gt_uint8)

            # 2. T√≠nh Periwound
            peri_l, peri_a, peri_b = analyze_periwound(image_resized, mask_gt_uint8, width=PERIWOUND_WIDTH)

            # L∆∞u
            feature_dict = {
                "image_name": os.path.basename(img_path),
                "texture_contrast": con,
                "texture_homogeneity": homo,
                "texture_energy": ener,
                "texture_correlation": corr,
                "periwound_L": peri_l,
                "periwound_a": peri_a, # Quan tr·ªçng: ƒê·ªô ƒë·ªè
                "periwound_b": peri_b
            }
            all_features_extra.append(feature_dict)

        except Exception as e:
            print(f"L·ªói: {e}")

    print(f"\n‚úÖ‚úÖ‚úÖ Ho√†n t·∫•t! ƒê√£ tr√≠ch xu·∫•t th√™m features.")

    # --- PH·∫¶N 3: GH√âP V√Ä L∆ØU FINAL CSV ---

    # Load l·∫°i file CSV hi·ªán t·∫°i (n·∫øu df_features_final kh√¥ng c√≥ s·∫µn)
    CSV_PATH_FINAL = "wound_features_dataset.csv"
    if 'df_features_final' not in globals():
        if os.path.exists(CSV_PATH_FINAL):
            df_features_final = pd.read_csv(CSV_PATH_FINAL)
        else:
            print("L·ªñI: Kh√¥ng t√¨m th·∫•y file CSV c≈©.")

    if 'df_features_final' in globals():
        # T·∫°o DataFrame m·ªõi
        df_extra = pd.DataFrame(all_features_extra)

        # Gh√©p
        print("ƒêang gh√©p (merge) c√°c features cu·ªëi c√πng...")
        df_features_complete = pd.merge(
            df_features_final,
            df_extra,
            on="image_name",
            how="left"
        )

        # L∆∞u Final
        df_features_complete.to_csv(CSV_PATH_FINAL, index=False)
        print(f"‚úÖ‚úÖ‚úÖ XONG! File CSV ho√†n ch·ªânh ƒë√£ ƒë∆∞·ª£c l∆∞u: {CSV_PATH_FINAL}")

        print("\n--- 5 d√≤ng ƒë·∫ßu c·ªßa DATASET HO√ÄN CH·ªàNH: ---")
        print(df_features_complete.head())
        df_features_complete.info()


# In[29]:


import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv("wound_features_dataset.csv")

colors = ['firebrick', 'gold', 'black']
cols   = ['pct_red_like', 'pct_yellow_like', 'pct_dark_like']
titles = ['Red', 'Yellow', 'Dark']

fig, ax = plt.subplots(1, 3, figsize=(20, 6))

for i in range(3):
    values_pct = df[cols[i]] * 100   # ‚ö° nh√¢n 100 ƒë·ªÉ th√†nh %
    sns.histplot(values_pct, kde=True, ax=ax[i],
                 color=colors[i], bins=30)
    ax[i].set_title(titles[i], fontsize=14)
    ax[i].set_xlabel("T·ª∑ l·ªá ph·∫ßn trƒÉm (%)")
    ax[i].set_ylabel("S·ªë l∆∞·ª£ng ·∫£nh")
    ax[i].set_xlim(0, 100)          # gi·ªù m·ªõi h·ª£p l√Ω

plt.suptitle("Ph√¢n ph·ªëi t·ª∑ l·ªá c√°c lo·∫°i m√¥ trong Dataset (986 ·∫£nh)", fontsize=16)
plt.tight_layout()
plt.show()


# In[30]:


print("--- 3. MA TR·∫¨N T∆Ø∆†NG QUAN (CORRELATION HEATMAP) ---")

# Ch·ªçn c√°c c·ªôt quan tr·ªçng ƒë·ªÉ soi
cols_to_analyze = [
    'pct_red_like', 'pct_yellow_like', 'pct_dark_like', # M√†u v·∫øt lo√©t
    'area_pixels', 'circularity',                    # H√¨nh th√°i
    'texture_contrast', 'texture_homogeneity',       # G·ªì gh·ªÅ
    'periwound_a', 'periwound_L', 'periwound_b'                     # Da xung quanh
]

# T√≠nh ma tr·∫≠n t∆∞∆°ng quan
corr_matrix = df[cols_to_analyze].corr()

# V·∫Ω Heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm', center=0, linewidths=0.5)
plt.title("M·ªëi t∆∞∆°ng quan gi·ªØa c√°c ƒë·∫∑c tr∆∞ng (Features)", fontsize=16)
plt.show()


# In[34]:


import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.feature_selection import f_classif

sns.set(style="whitegrid", font_scale=1.0)

# 1. Load data
df = pd.read_csv("/kaggle/input/additional/wound_features_dataset (1).csv")

# 2. Ch·ªçn c√°c c·ªôt feature ƒë·ªÉ ph√¢n t√≠ch (b·ªè image_name, split,‚Ä¶)
feature_cols = [
    "pct_red_like",
    "pct_yellow_like",
    "pct_dark_like",
    "area_pixels",
    "perimeter",
    "circularity",
    "texture_contrast",
    "texture_homogeneity",
    "texture_energy",
    "texture_correlation",
    "periwound_L",
    "periwound_a",
    "periwound_b"
]

X = df[feature_cols].copy()

print("Shape feature matrix:", X.shape)


# In[35]:


# === CLUSTERED HEATMAP C·ª¶A MA TR·∫¨N T∆Ø∆†NG QUAN ===

corr = X.corr()

g = sns.clustermap(
    corr,
    cmap="coolwarm",
    center=0,
    linewidths=0.5,
    annot=True,
    fmt=".2f",
    figsize=(10, 8)
)
plt.setp(g.ax_heatmap.get_xticklabels(), rotation=45, ha="right")
plt.setp(g.ax_heatmap.get_yticklabels(), rotation=0)
g.fig.suptitle("Clustered Heatmap ‚Äì T∆∞∆°ng quan gi·ªØa c√°c ƒë·∫∑c tr∆∞ng", y=1.02)
plt.show()


# In[38]:


import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import seaborn as sns
import matplotlib.pyplot as plt

# 1. Load l·∫°i dataset
df = pd.read_csv("/kaggle/input/additional/wound_features_dataset (1).csv")

# 2. Ch·ªçn c√°c feature numerical
feature_cols = [
    "pct_red_like", "pct_yellow_like", "pct_dark_like",
    "area_pixels", "perimeter", "circularity",
    "texture_contrast", "texture_homogeneity",
    "texture_energy", "texture_correlation",
    "periwound_L", "periwound_a", "periwound_b"
]

X = df[feature_cols].copy()

# 3. Chu·∫©n h√≥a d·ªØ li·ªáu
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 4. PCA 3 components
pca = PCA(n_components=3, random_state=42)
X_pca = pca.fit_transform(X_scaled)

print("Explained variance ratio:", pca.explained_variance_ratio_)

# 5. PCA loadings (ƒë√≥ng g√≥p c·ªßa t·ª´ng feature l√™n t·ª´ng PC)
loadings = pd.DataFrame(
    pca.components_.T,
    index=feature_cols,
    columns=['PC1', 'PC2', 'PC3']
)

print("\n=== PCA LOADINGS ===")
print(loadings)

# 6. V·∫Ω heatmap loadings
plt.figure(figsize=(8, 6))
sns.heatmap(loadings, annot=True, fmt=".2f",
            cmap="coolwarm", center=0)
plt.title("PCA Loading Plot (ƒê√≥ng g√≥p c·ªßa t·ª´ng feature l√™n PC1‚ÄìPC3)")
plt.tight_layout()
plt.show()


# In[39]:


import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt

# 1. Load data
df = pd.read_csv("/kaggle/input/additional/wound_features_dataset (1).csv")

# 2. Ch·ªçn to√†n b·ªô c√°c feature numeric
feature_cols = [
    "pct_red_like", "pct_yellow_like", "pct_dark_like",
    "area_pixels", "perimeter", "circularity",
    "texture_contrast", "texture_homogeneity",
    "texture_energy", "texture_correlation",
    "periwound_L", "periwound_a", "periwound_b"
]

X = df[feature_cols].copy()

# 3. Standardize
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 4. Ch·∫°y K = 2..10
K_list = list(range(2, 11))
inertias = []
sil_scores = []

for K in K_list:
    kmeans = KMeans(n_clusters=K, random_state=42, n_init=10)
    labels = kmeans.fit_predict(X_scaled)

    inertias.append(kmeans.inertia_)
    sil = silhouette_score(X_scaled, labels)
    sil_scores.append(sil)

    print(f"K={K}: inertia={kmeans.inertia_:.2f}, silhouette={sil:.4f}")

# 5. V·∫Ω bi·ªÉu ƒë·ªì Elbow + Silhouette
fig, ax = plt.subplots(1, 2, figsize=(14, 5))

# Elbow
ax[0].plot(K_list, inertias, marker='o')
ax[0].set_title("Elbow Method (Inertia)")
ax[0].set_xlabel("S·ªë c·ª•m (K)")
ax[0].set_ylabel("Inertia")

# Silhouette
ax[1].plot(K_list, sil_scores, marker='o')
ax[1].set_title("Silhouette Score")
ax[1].set_xlabel("S·ªë c·ª•m (K)")
ax[1].set_ylabel("Silhouette score")

plt.tight_layout()
plt.show()


# In[40]:


import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import seaborn as sns
import matplotlib.pyplot as plt

# Load file
df = pd.read_csv("/kaggle/input/additional/wound_features_dataset (1).csv")

# Ch·ªçn feature numeric
feature_cols = [
    "pct_red_like", "pct_yellow_like", "pct_dark_like",
    "area_pixels", "perimeter", "circularity",
    "texture_contrast", "texture_homogeneity",
    "texture_energy", "texture_correlation",
    "periwound_L", "periwound_a", "periwound_b"
]

X = df[feature_cols].copy()

# Standardize
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ==========================
#   KMEANS K = 3
# ==========================
kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
clusters = kmeans.fit_predict(X_scaled)

df["cluster_raw"] = clusters

# ==========================
#   ƒê·ªîI T√äN CLUSTER
#   (d·ª±a tr√™n centroid severity)
# ==========================
cent = pd.DataFrame(kmeans.cluster_centers_, columns=feature_cols)

# Severity score = weight color + size + texture
severity_score = (
    cent["pct_dark_like"]*2 +
    cent["pct_yellow_like"]*1.5 +
    cent["area_pixels"]*1.4 +
    cent["texture_contrast"]*1.2 -
    cent["pct_red_like"]*1.3 +
    -cent["periwound_L"]*0.7
)

order = np.argsort(severity_score)  # nh·ªè nh·∫•t ‚Üí l·ªõn nh·∫•t = low ‚Üí high

mapping = {
    order[0]: "low",
    order[1]: "medium",
    order[2]: "high"
}

df["risk_level"] = df["cluster_raw"].map(mapping)

print("Mapping severity:", mapping)
print(df[["image_name", "risk_level"]].head())


# In[41]:


# PCA 2D
pca = PCA(n_components=2, random_state=42)
X_pca = pca.fit_transform(X_scaled)

df["PC1"] = X_pca[:,0]
df["PC2"] = X_pca[:,1]

print("Explained variance:", pca.explained_variance_ratio_)

plt.figure(figsize=(8,6))
sns.scatterplot(
    data=df,
    x="PC1",
    y="PC2",
    hue="risk_level",
    palette={"low":"green", "medium":"orange", "high":"red"},
    s=40,
    alpha=0.85
)
plt.title("PCA 2D ‚Äì Cluster K=3 (Low / Medium / High Risk)")
plt.axhline(0, color="grey", linewidth=0.4)
plt.axvline(0, color="grey", linewidth=0.4)
plt.tight_layout()
plt.show()


# In[42]:


# standardized dataframe
X_scaled_df = pd.DataFrame(X_scaled, columns=feature_cols)
X_scaled_df["risk_level"] = df["risk_level"]

cluster_profile = X_scaled_df.groupby("risk_level")[feature_cols].mean()

plt.figure(figsize=(10,5))
sns.heatmap(cluster_profile, annot=True, fmt=".2f",
            cmap="coolwarm", center=0)
plt.title("Cluster Profile ‚Äì Mean Z-score (Low / Medium / High Risk)")
plt.xlabel("Feature")
plt.ylabel("Risk Group")
plt.tight_layout()
plt.show()


# In[43]:


df.to_csv("wound_features_with_risk.csv", index=False)
print("ƒê√£ l∆∞u file wound_features_with_risk.csv")

